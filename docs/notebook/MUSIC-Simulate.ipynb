{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSIC (MUltiple SIgnal Classification) Notebook - SIMULATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***This notebook is essentially a copy of the MUSIC.ipynb, except that it shows how to insert artificial MSTID's into the data processing stream for the purpose of evaluating the processing algorithms.***\n",
    "\n",
    "<a href=\"#simulate\">Click here to jump to the part where the data simulator is used.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[simulate]: The MUSIC (MUltiple SIgnal Classification) algorithm is a rather generic and well-know algorithm in signal process used for the detection of multiple waves within an array of sensors [Schmidt, 1986].  MUSIC was originally used in SuperDARN by Samson et al. [1990] and Bristow et al. [1994] for the estimation of the characteristics of Medium Scale Traveling Ionospheric Disturbances (MSTIDs) detected by SuperDARN Radars.  These papers have inspired this implementation of the MUSIC algorithm.\n",
    "\n",
    "While this code has been written with SuperDARN detected MSTIDs in mind, it may be useful for working with other wave-like perturbations moving across the field of view of some geophysical instrument.\n",
    "\n",
    "This notebook demonstrates the use of the DaViTPy MUSIC module for MSTID parameter estimation.\n",
    "\n",
    "The DaViTPy MUSIC module is used by creating a musicArray object, which includes built-in methods for keeping track of all steps in the processing algorithm.  As the data is processed, all preceeding variants of the data are saved within the object and a history is created.  This makes it very easy to see what has been done with the data at any step along the way.\n",
    "\n",
    "*Written by N.A. Frissell, 4 November 2013.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "\n",
    "Bristow, W. A., R. A. Greenwald, and J. C. Samson (1994), Identification of high-latitude acoustic gravity wave sources using the Goose Bay HF Radar, J. Geophys. Res., 99(A1), 319–331, doi:10.1029/93JA01470.\n",
    "\n",
    "Samson, J. C., R. A. Greenwald, J. M. Ruohoniemi, A. Frey, and K. B. Baker (1990), Goose Bay radar observations of Earth-reflected, atmospheric gravity waves in the high-latitude ionosphere, J. Geophys. Res., 95(A6), 7693–7709, doi:10.1029/JA095iA06p07693.\n",
    "\n",
    "Schmidt, R.O., \"Multiple emitter location and signal parameter estimation,\" Antennas and Propagation, IEEE Transactions on, vol.34, no.3, pp.276,280, Mar 1986, doi:10.1109/TAP.1986.1143830."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "#Import the modules we need.\n",
    "%pylab inline\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from davitpy import pydarn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MUSIC Processing Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Basic Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'buffer' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f5592b23ce50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0meTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2011\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmyPtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydarn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msdio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradDataOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msTime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meTime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/wpad/code_other/davitpy/davitpy/pydarn/sdio/radDataRead.pyc\u001b[0m in \u001b[0;36mradDataOpen\u001b[0;34m(sTime, radcode, eTime, channel, bmnum, cp, fileType, filtered, src, fileName, noCache, local_dirfmt, local_fnamefmt, local_dict, remote_dirfmt, remote_fnamefmt, remote_dict, remote_site, username, password, port, tmpdir)\u001b[0m\n\u001b[1;32m    167\u001b[0m                        \u001b[0mremote_fnamefmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremote_fnamefmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_site\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremote_site\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                        \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                        \u001b[0mstid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRadarByCode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                        tmpdir=tmpdir)\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmyPtr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wpad/code_other/davitpy/davitpy/pydarn/radar/radStruct.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillFromSqlite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdbname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/wpad/code_other/davitpy/davitpy/pydarn/radar/radStruct.py\u001b[0m in \u001b[0;36mfillFromSqlite\u001b[0;34m(self, dbname, radId)\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'buffer' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "#Choose the radar and time of the data that we want to look at.\n",
    "#Then, connect to the data source using the standard DaViTPy\n",
    "#pydarn.sdio.radDataOpen() routine.\n",
    "\n",
    "rad='wal'\n",
    "sTime = datetime.datetime(2011,5,9,8)\n",
    "eTime = datetime.datetime(2011,5,9,19)\n",
    "\n",
    "myPtr = pydarn.sdio.radDataOpen(sTime,rad,eTime=eTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the data object.\n",
    "\n",
    "# By creating this object, data is taken from the SuperDARN database and rearranged into a numpy.array with\n",
    "# the shape (Nr Times, Nr Beams, Nr Gates).  Missing data is stored as np.nan.\n",
    "\n",
    "# By default, this command only loads in data where the ground scatter flag is True.\n",
    "\n",
    "# The fovModel='GS' indicates to calculate the field-of-view coordinates in using the ground-scatter mapping\n",
    "# formula.  This is standard when looking at MSTIDs using ground scatter.  See Bristow et al. [1994] for details.\n",
    "dataObj     = pydarn.proc.music.musicArray(myPtr,fovModel='GS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can list all of the data sets stored in this object.  Right now there is only one data set, but\n",
    "# as we go along, each step of processing will create a new data set.\n",
    "\n",
    "# Each data set is simply stored as an attribute of the dataObj, but the names of all of the data sets can be\n",
    "# accessed through the get_data_sets() method.\n",
    "dataObj.get_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the data set is saved in it's metadata dictionary.  Some of the information in the metadata\n",
    "# dictionary is used to control certain plotting and processing variables in this module.\n",
    "\n",
    "dataObj.DS000_originalFit.printMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The music module also keeps track of each step of processing in using the data set's history attribute.\n",
    "\n",
    "dataObj.DS000_originalFit.printHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 'active' attribute of dataObj is a reference to the most recently used data set of dataObj.  It is also\n",
    "# the default data set used by all DaViTPy MUSIC processing and plotting routines.  You can see this command\n",
    "# produces the same result as the cell above.\n",
    "\n",
    "dataObj.active.printHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can create an RTI plot and a fan plot from the data we loaded.\n",
    "# You can see that both range gate and geographic latitude are given on the y-axis, and the solar terminator\n",
    "# is also shaded in.  The terminator does not go below approximately range gate 10.  This is because the ground\n",
    "# scatter mapping formula is not defined for close-in range gates.\n",
    "\n",
    "fig = pydarn.plotting.musicRTI(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also make a fan plot.\n",
    "plotTime = datetime.datetime(2011,5,9,14)\n",
    "fig = pydarn.plotting.musicFan(dataObj,time=plotTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to focus on just the data that contains the MSTID we are looking for, so we can apply some limits.\n",
    "\n",
    "# proc.music.defineLimits() does not actually modify the data, it just marks the data by putting an an entry\n",
    "# into the dataObj.active.metadata dictionary.  The limits will be applied later.  Right now, you can see\n",
    "# what data will be eliminated by making a new RTI plot.\n",
    "\n",
    "pydarn.proc.music.defineLimits(dataObj,gateLimits=[30,45])\n",
    "fig = pydarn.plotting.musicRTI(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also to restrict the amount of time we process.  Before actually running the music algorithm, we\n",
    "# will be filtering the data using a FIR filter that will eat up data at the beginning and end of the filter.\n",
    "# We can calculate exactly how much time that will be if we know some of the filter characteristics and\n",
    "# the time resolution of the data.  This can then be used to give us new start and end times.\n",
    "\n",
    "# For now, let's say we are going to use a filter with 101 taps and a dataset with 120 s resolution.\n",
    "numtaps = 101\n",
    "timeres = 120\n",
    "\n",
    "#Let's also say that we are interested in the MSTID feature between 1400 and 1600 UT.\n",
    "sTime_of_interest = datetime.datetime(2011,5,9,14)\n",
    "eTime_of_interest = datetime.datetime(2011,5,9,16)\n",
    "\n",
    "#Now calculate the new start and end times...\n",
    "new_times = pydarn.proc.music.filterTimes(sTime_of_interest, eTime_of_interest, timeres, numtaps)\n",
    "pydarn.proc.music.defineLimits(dataObj,timeLimits=new_times)\n",
    "\n",
    "fig = pydarn.plotting.musicRTI(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we apply the limits and replot once more.\n",
    "# Note that many of the processing routines will automatically call applyLimits() before they\n",
    "# run the processing algorithm.\n",
    "\n",
    "dataObj.active.applyLimits()\n",
    "fig = pydarn.plotting.musicRTI(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that a new data set was created when we applied the limits.\n",
    "dataObj.get_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also note that the history of the new object was updated.\n",
    "dataObj.active.printHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation and Cartesian Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before we feed into the MUSIC Algorithm, we don't want our data to have any gaps in time or space.\n",
    "# Let's start by interpolating in space along the beams.\n",
    "pydarn.proc.music.beamInterpolation(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,10))\n",
    "ax  = fig.add_subplot(121)\n",
    "pydarn.plotting.musicPlot.musicFan(dataObj,plotZeros=True,dataSet='originalFit',axis=ax,time=plotTime)\n",
    "ax  = fig.add_subplot(122)\n",
    "pydarn.plotting.musicPlot.musicFan(dataObj,plotZeros=True,axis=ax,time=plotTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to interpolate in time.  timeres=120 [seconds] was set in an earlier cell.\n",
    "pydarn.proc.music.timeInterpolation(dataObj,timeRes=timeres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydarn.plotting.musicPlot.timeSeriesMultiPlot(dataObj,dataSet='timeInterpolated',dataSet2='beamInterpolated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want need to calculate a local cartesian grid for each cell we are going to use.\n",
    "pydarn.proc.music.determineRelativePosition(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The black cell marks the center of the array.\n",
    "fig = pydarn.plotting.plotRelativeRanges(dataObj,time=plotTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name='simulate' />Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, we can inject a simulated MSTID into the processing chain.  This way, we can see exactly what\n",
    "# processing is doing to ideal data.  It is really easy to inject a default simulated wave.\n",
    "pydarn.proc.music.simulator(dataObj)\n",
    "fig = pydarn.plotting.musicRTI(dataObj)\n",
    "fig = pydarn.plotting.musicFan(dataObj,time=plotTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Or, you can do something more complicated.  Here we define two custom MSTIDs and add some noise.\n",
    "# Each MSTID is evaluated as a cosine and then summed together.  The cosine evaluated is::\n",
    "# sig  = amp * np.cos(kx*xgrid + ky*ygrid - 2.*np.pi*f*t + phi) + dc\n",
    "\n",
    "sigs = []\n",
    "#           (amp,    kx,      ky,      f, phi, dcOffset)\n",
    "sigs.append((  5,  -0.01,   0.010, 0.0007,   0,       5.))\n",
    "sigs.append((  10, 0.022,  -0.023, 0.0004,   0,       5.))\n",
    "\n",
    "#And some arbitrary white gaussian noise...\n",
    "noiseFactor = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydarn.proc.music.simulator(dataObj,sigs=sigs,noiseFactor=noiseFactor)\n",
    "fig = pydarn.plotting.musicRTI(dataObj)\n",
    "fig = pydarn.plotting.musicFan(dataObj,time=plotTime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter the data.\n",
    "# numtaps=101 was set in an above cell.  The cutoff_frequencies are in Hz.\n",
    "filt = pydarn.proc.music.filter(dataObj, numtaps=numtaps, cutoff_low=0.0003, cutoff_high=0.0012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At this point, the data has been filtered and saved to a new data set in dataObj.\n",
    "# Before we look at the data, let's look at the transfer function and impulse response of the data.\n",
    "\n",
    "fig = filt.plotTransferFunction(xmax=0.004)\n",
    "fig = filt.plotImpulseResponse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the filtered RTI plot.  We should set autoScale to True since the magnitudes will be much\n",
    "# lower than the original data.\n",
    "\n",
    "fig = pydarn.plotting.musicRTI(dataObj,autoScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can see that the filter already marked off the data that you shouldn't use.\n",
    "# Just applyLimits() and replot.\n",
    "dataObj.active.applyLimits()\n",
    "fig = pydarn.plotting.musicRTI(dataObj,autoScale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a fan plot.\n",
    "fig = pydarn.plotting.musicFan(dataObj,time=plotTime,autoScale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectral Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have now run all of the processing needed to feed the data into the spectral analysis and MUSIC.\n",
    "# Let's print the history just to recap what we have done.\n",
    "dataObj.active.printHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing to do is to calculate the FFT of every cell...\n",
    "pydarn.proc.music.calculateFFT(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the spectrum of select cells...\n",
    "pydarn.plotting.spectrumMultiPlot(dataObj,xlim=(-0.0025,0.0025))\n",
    "pydarn.plotting.musicPlot.spectrumMultiPlot(dataObj,plotType='magnitude',xlim=(0,0.0025))\n",
    "pydarn.plotting.musicPlot.spectrumMultiPlot(dataObj,plotType='phase',xlim=(0,0.0025))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also plot the full spectrum.  Here, every FFT bin contains 16 slices,\n",
    "# showing the data for each of the 16 radar beams from left to right.\n",
    "# Range gates are shown on the y-axis.\n",
    "pydarn.plotting.plotFullSpectrum(dataObj,xlim=(0,0.00175))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MUSIC Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cross-spectral matrix Dlm.\n",
    "pydarn.proc.music.calculateDlm(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the Dlm matrix.  This usually isn't necessary for routine processing, but\n",
    "# it is good to know where the numbers are going...\n",
    "pydarn.plotting.plotDlm(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we finally run detect the horizontal wave numbers.\n",
    "pydarn.proc.music.calculateKarr(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then plot the final result.\n",
    "pydarn.plotting.musicPlot.plotKarr(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we can see all of the history gone into processing this plot.\n",
    "dataObj.active.printHistory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature/Signal Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the image processing library in scikit-image to automatically find the peaks representing signals.\n",
    "pydarn.proc.music.detectSignals(dataObj)\n",
    "pydarn.plotting.musicPlot.plotKarr(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All of the parameters connected with these signals is located in the sigDectect attribute.\n",
    "dataObj.active.sigDetect.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get some insight on how the signal processing algorithm works, we can plot the detected groups.\n",
    "# You can adjust the threshold and neighborhood keywords on pydarn.proc.music.detectSignals() to tweak\n",
    "# the autodetection.\n",
    "pydarn.plotting.plotKarrDetected(dataObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
